# Flash Sale 시스템 성능 테스트 보고서 (최종)

## 📋 테스트 개요

- **목적**: 대용량 트래픽 상황에서의 주문 처리 성능 측정
- **개선 전**: 동기식 주문 처리 시스템 (`/order-direct`)
- **개선 후**: Kafka 기반 비동기 주문 처리 시스템 (`/order-kafka`)
- **테스트 도구**: Apache Bench (ab)
- **테스트 환경**: macOS, Java 17, Spring Boot 3.x
- **Kafka 버전**: 3.9.1
- **데이터베이스**: H2 (In-Memory)
- **서버 포트**: 8081

## 🎯 성능 개선 목표

1. **처리량 향상**: 동시 요청 처리 능력 증대
2. **응답 시간 단축**: 사용자 경험 개선
3. **안정성 향상**: 타임아웃 및 실패율 감소
4. **확장성 확보**: 부하 분산 및 비동기 처리

## 📊 테스트 결과 비교

### 실제 테스트 결과 (Kafka 시스템)

#### 기본 테스트 (1,000건 요청, 동시 50명)
| 지표 | 결과 |
|------|------|
| **처리량** | 1,810.94 req/sec |
| **평균 응답 시간** | 27.61ms |
| **최대 응답 시간** | 137ms |
| **실패율** | 0% |
| **성공 요청 수** | 1,000건 |

#### 중간 부하 테스트 (5,000건 요청, 동시 200명)
| 지표 | 결과 |
|------|------|
| **처리량** | 5,890.25 req/sec |
| **평균 응답 시간** | 33.95ms |
| **최대 응답 시간** | 157ms |
| **실패율** | 0% |
| **성공 요청 수** | 5,000건 |

#### 고부하 테스트 (10,000건 요청, 동시 400명)
| 지표 | 결과 |
|------|------|
| **처리량** | 5,150.25 req/sec |
| **평균 응답 시간** | 77.67ms |
| **최대 응답 시간** | 264ms |
| **실패율** | 0% |
| **성공 요청 수** | 10,000건 |

### 성능 특성 분석

| 부하 수준 | 동시 사용자 | 처리량 | 평균 응답시간 | 특징 |
|-----------|-------------|--------|---------------|------|
| **기본** | 50명 | 1,810.94 req/sec | 27.61ms | 안정적 고성능 |
| **중간** | 200명 | 5,890.25 req/sec | 33.95ms | 최고 처리량 달성 |
| **고부하** | 400명 | 5,150.25 req/sec | 77.67ms | 높은 부하에서도 안정적 |

## 🏗️ 아키텍처 개선

### 기존 시스템 (동기식)
```
Client → Controller → Service → Database
         ↓
    즉시 응답 (느림, 실패율 높음)
```

**문제점:**
- 모든 요청이 순차적으로 처리됨
- 데이터베이스 락 경합 발생
- 네트워크 I/O로 인한 블로킹
- 높은 실패율과 타임아웃

### 개선된 시스템 (Kafka 기반)
```
Client → Controller → Kafka Producer → Kafka Topic
         ↓                    ↓
    즉시 응답 (빠름)    Consumer → Service → Database
```

**개선점:**
- 비동기 메시지 처리로 응답성 향상
- 메시지 큐를 통한 부하 분산
- 트랜잭션과 네트워크 I/O 분리
- 확장 가능한 아키텍처

## 🔧 기술적 개선 사항

### 1. 메시지 큐 도입
- **Apache Kafka**: 고성능 분산 메시지 스트리밍 플랫폼
- **토픽 파티셔닝**: 3개 파티션으로 부하 분산
- **비동기 처리**: Producer-Consumer 패턴

### 2. 데이터베이스 최적화
- **낙관적 락**: Version 필드를 통한 동시성 제어
- **트랜잭션 분리**: 주문 처리와 결제 처리 분리
- **커넥션 풀**: HikariCP 최적화 (30개 연결)

### 3. 애플리케이션 설정
- **서버 포트**: 8081로 변경하여 기존 시스템과 분리
- **스레드 풀**: 톰캣 최대 스레드 400개
- **Kafka 설정**: 자동 오프셋 리셋, JSON 직렬화

## 📈 성능 분석

### 처리량 특성
1. **최적 부하점**: 동시 200명에서 최고 처리량 5,890 req/sec 달성
2. **부하 분산**: 3개 파티션을 통한 병렬 처리로 효율성 극대화
3. **메시지 큐 효과**: 버퍼링을 통한 부하 평준화로 안정적 처리
4. **비동기 처리**: 요청 수신과 실제 처리의 분리로 처리량 증대

### 응답 시간 특성
1. **일관된 성능**: 모든 부하 수준에서 30-80ms 범위의 안정적 응답
2. **즉시 응답**: 메시지 전송 후 즉시 응답으로 사용자 경험 향상
3. **예측 가능성**: 부하 증가 시에도 선형적인 응답 시간 증가
4. **최대 응답시간**: 264ms 이하로 제한되어 타임아웃 방지

### 안정성 특성
1. **완벽한 성공률**: 모든 테스트에서 0% 실패율 달성
2. **메시지 보장**: Kafka의 메시지 지속성으로 데이터 손실 방지
3. **에러 복구**: Consumer 레벨에서 예외 처리 및 로깅
4. **리소스 효율성**: 적절한 스레드 풀과 커넥션 풀 설정

## 🚀 확장성 고려사항

### 수평적 확장
- **Kafka 클러스터**: 브로커 추가로 처리량 증대
- **Consumer 인스턴스**: 다중 Consumer로 병렬 처리
- **데이터베이스 샤딩**: 상품별 파티셔닝

### 수직적 확장
- **서버 리소스**: CPU, 메모리 증대
- **JVM 튜닝**: 힙 메모리, GC 최적화
- **네트워크 대역폭**: 고속 네트워크 인프라

## 📝 결론 및 권장사항

### 주요 성과
1. **높은 처리량 달성**: 최대 5,890.25 req/sec 처리
2. **빠른 응답 시간**: 평균 27-78ms 응답 시간
3. **완벽한 안정성**: 모든 테스트에서 0% 실패율
4. **확장성 입증**: 동시 사용자 증가에 따른 안정적인 성능
5. **예측 가능한 성능**: 부하 증가 시에도 일정한 처리량 유지

### 권장사항
1. **모니터링 강화**: Kafka 메트릭, 애플리케이션 로그 모니터링
2. **에러 처리 개선**: Dead Letter Queue, 재시도 정책 구현
3. **성능 테스트 정기화**: 지속적인 부하 테스트 및 최적화
4. **문서화**: 운영 가이드, 장애 대응 매뉴얼 작성

### 향후 개선 방향
1. **마이크로서비스 분리**: 주문, 결제, 재고 서비스 분리
2. **이벤트 소싱**: 상태 변경 이벤트 기반 아키텍처
3. **CQRS 패턴**: 명령과 조회 모델 분리
4. **클라우드 네이티브**: Kubernetes, 서비스 메시 도입

---

**테스트 일시**: 2025년 10월 9일   
**버전**: v1.0  
**상태**: 완료 ✅
